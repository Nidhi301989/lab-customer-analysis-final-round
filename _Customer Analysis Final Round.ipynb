{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaeeb2fc",
   "metadata": {},
   "source": [
    "# Lab | Customer Analysis Final Round\n",
    "\n",
    "1.Problem (case study)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ceeec1",
   "metadata": {},
   "source": [
    "Data Description:\n",
    "The dataset marketing_customer_analysis.csv contains various features related to customer demographics, insurance policy details, and customer interactions.\n",
    "\n",
    "Goal:\n",
    "The goal is to predict the Total Claim Amount using a linear regression model and validate the model using various metrics such as R², MSE, RMSE, and MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef4afcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.Getting Data\n",
    "# Read the .csv file:\n",
    "    \n",
    "   import pandas as pd\n",
    "\n",
    "file_path = 'path_to_your_file/marketing_customer_analysis.csv'\n",
    "data = pd.read_csv(file_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 - Cleaning/Wrangling/EDA\n",
    "# Change headers names:\n",
    "\n",
    "data.columns = data.columns.str.lower().str.replace(' ', '_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e02ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with NaN values:\n",
    "\n",
    "# Fill numerical columns with the median\n",
    "for col in data.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "# Fill categorical columns with the most frequent value\n",
    "for col in data.select_dtypes(include=['object']).columns:\n",
    "    data[col].fillna(data[col].value_counts().idxmax(), inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019eb1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Features and Numerical Features:\n",
    "\n",
    "categorical_features = data.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_features = data.select_dtypes(exclude=['object']).columns.tolist()\n",
    "numerical_features.remove('total_claim_amount')  # Exclude target variable from features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269f34a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration:\n",
    "\n",
    "data.describe()  # Summary statistics\n",
    "data.info()  # Data types and missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8099f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 - Processing Data\n",
    "# Dealing with outliers:\n",
    "\n",
    "# Assuming using IQR method for numerical features\n",
    "for col in numerical_features:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    data = data[(data[col] >= lower_bound) & (data[col] <= upper_bound)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b133ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[numerical_features] = scaler.fit_transform(data[numerical_features])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7dbcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding Categorical Data:\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numerical_features),\n",
    "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67871737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train set and test set:\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(columns=['total_claim_amount'])\n",
    "y = data['total_claim_amount']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d714844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 - Modeling\n",
    "# Apply model:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92acb802",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 - Model Validation\n",
    "# R2, MSE, RMSE, MAE:\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"R-squared (R²) score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ad98cf",
   "metadata": {},
   "source": [
    "7 - Reporting\n",
    "Present results:\n",
    "\n",
    "Presenting the results using a summary of the metrics calculated:\n",
    "\n",
    "1.Mean Squared Error (MSE): Measures the average of the squares of the errors.\n",
    "2.Root Mean Squared Error (RMSE): The square root of the MSE, providing error in the same units as the target variable.\n",
    "3.Mean Absolute Error (MAE): The average of the absolute differences between the predicted and actual values.\n",
    "4.R-squared (R²): Indicates how well the model explains the variability of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1777e72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 78784.0914895\n",
      "R^2 Score: -0.1642047460942666\n"
     ]
    }
   ],
   "source": [
    "#Complete Script\n",
    "#Here is the complete script in one go:\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Sample Data\n",
    "np.random.seed(0)\n",
    "data = {\n",
    "    'Age': np.random.randint(20, 70, size=1000),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], size=1000),\n",
    "    'Income': np.random.randint(20000, 80000, size=1000),\n",
    "    'Region': np.random.choice(['North', 'South', 'East', 'West'], size=1000),\n",
    "    'Purchase_Amount': np.random.randint(100, 1000, size=1000)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Splitting the data\n",
    "X = df.drop('Purchase_Amount', axis=1)\n",
    "y = df['Purchase_Amount']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Defining the preprocessing pipelines for both numeric and categorical data\n",
    "numeric_features = ['Age', 'Income']\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_features = ['Gender', 'Region']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combining the numeric and categorical pipelines\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Creating the model pipeline\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=0))\n",
    "])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Model Validation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R^2 Score:\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17da5a12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
